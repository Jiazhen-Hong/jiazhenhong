<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiazhen Hong</title>

    <meta name="author" content="Jiazhen Hong">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
    <style>
      .publication-entry {
        display: flex;
        flex-direction: row;
        align-items: center;
        margin-bottom: 20px;
        padding-left: 20px; /* Add padding to align with Research section */
      }
    
      .publication-entry img,
      .publication-entry video {
        margin-right: 20px;
        max-width: 300px; /* Set a fixed larger width for images/videos */
        width: 100%; /* Ensure it adapts to smaller screens */
        height: auto; /* Maintain aspect ratio */
        object-fit: cover;
      }
    
      .publication-entry .publication-text {
        flex: 1;
        font-size: 0.9em; /* Slightly reduce the text size */
        line-height: 1.5; /* Increase line spacing for better readability */
      }
    
      .publication-entry .papertitle {
        font-weight: bold;
        color: #0070C0; /* Blue color for titles to make them stand out */
      }
    
      .publication-section {
        margin-left: 20px;
        padding-left: 20px; /* Adjust to match the Research section padding */
      }
    
      .publication-section h3 {
        margin-left: -20px;
      }
    
      .publication-section ul {
        list-style-type: disc;
        padding-left: 20px;
      }
    
      .publication-section li {
        margin-bottom: 10px;
      }
    </style>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Jiazhen Hong | Ê¥™ÂòâÊ°¢
                    </p>
                    <p>
                      <a href="https://www.ece.rutgers.edu/"> Department of Electrical and Computer Engineering at Rutgers University</a> in Piscataway, NJ.
                    </p>
                    <p>
                      I am currently working at the <a href="https://eceweb1.rutgers.edu/~laleh/#/">Integrated Systems & NeuroImaging Laboratory</a> at Rutgers University, advised by Professor <a href="https://eceweb1.rutgers.edu/~laleh/#/people/PI">Laleh Najafizadeh</a>, and part-time at <a href="https://www.emotiv.com/">Emotiv</a>, a global technology company specializing in the development and manufacturing of wearable EEG products. My primary research interests include time-series foundation models, electroencephalography (EEG)-based brain-computer interfaces (BCI), signal processing, and LLM-driven BCI applications.
                    </p> 
                    <p style="text-align:center">
                      <a href="mailto:jh1590@rutgers.edu">Email</a> &nbsp;/&nbsp;
                      <a href="data/JiazhenHong-Resume.pdf">Resume</a> &nbsp;/&nbsp;
                      <a href="data/JiazhenHong-bio.txt">Bio</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=EuF8xXgAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                      <a href="https://github.com/h128jj/">Github</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:40%;max-width:40%">
                    <a href="images/JiazhenHong.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JiazhenHong.jpg" class="hoverZoomLink"></a>
                  </td>
                </tr>
              </tbody>
            </table>
            
            <!-- Add News Section Here -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>üî• News</h2>
                    <ul>
                      <li style="padding-bottom: 6px;"><strong>2025.01.02:</strong> üî•üî• <a href="https://embc.embs.org/2025/">ChatBCI4ALS: A High-Performance, LLM-Driven Intent-Based BCI Communication System for Individuals with ALS </a>, is accpeted by 47th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2025), &nbsp<a href="https://embc.embs.org/2025/"><img src="logo/IEEE-EMBC.png" alt="EMBC Logo" style="width:60px; vertical-align: middle;"></a>  </li>
                      <li style="padding-bottom: 6px;"><strong>2025.03.04:</strong> ‚ú®‚ú® <a href="https://grad.rutgers.edu/">Travel Award</a>,  2024-2025 Cycle for Research & Conference Travel Award funding by the School of Graduate Studies (SGS), &nbsp<a href="https://grad.rutgers.edu/"><img src="logo/Rutgers-SGS.png" alt="IEEEBrain Logo" style="width:80px; vertical-align: middle;"></a> </li>
                      <li style="padding-bottom: 6px;"><strong>2025.02.28:</strong> ‚ú®‚ú® <a href="https://www.linkedin.com/feed/update/urn:li:activity:7302402411111895041/">Travel Award</a>, 2024‚Äê2025 Rutgers Brain Health Institute Trainee Travel Award by the Cognitive and Sensory Neuroscience Focus Area Working Group, &nbsp<a href="https://brainhealthinstitute.rutgers.edu/2024-2025-rutgers-brain-health-institute-trainee-travel-awards/"><img src="logo/RU-BHI-logo.png" alt="IEEEBrain Logo" style="width:60px; vertical-align: middle;"></a> </li>
                      <li style="padding-bottom: 6px;"><strong>2025.01.02:</strong> üî•üî• <a href="https://biomedicalimaging.org/2025/">TopoEEG: a TimeSformer-Based Topographic Image Representation Method for Early Single-Trial Detection of P300</a>, is accpeted by 22nd IEEE International Symposium on Biomedical Imaging (ISBI 2025), &nbsp<a href="https://biomedicalimaging.org/2025/"><img src="logo/ISBI2025.png" alt="IEEESignalProcessing Logo" style="width:30px; vertical-align: middle;"></a>  </li>
                      <li style="padding-bottom: 6px;"><strong>2024.10.01:</strong> üéâüéâ I am excited to start my new position as a Foundation Model/Generative AI Intern at the leading brain-computer interface company, &nbsp<a href="https://www.emotiv.com/"><img src="logo/Emotiv-logo-black.png" alt="Emotiv Logo" style="width:100px; vertical-align: middle;"></a></li>
                      <li style="padding-bottom: 4px;"><strong>2024.09.20:</strong> üî•üî• <a href="data/poster/IEEEbrain2024.pdf">ChatBCI: A Fast P300 Speller Brain-Computer Interface Incorporating Generative AI-Based Word Prediction</a>, is accpeted by 2024 IEEE Brain Discovery and Neurotechnology Workshop, &nbsp<a href="https://brain.ieee.org/"><img src="logo/IEEEBrain.png" alt="IEEEBrain Logo" style="width:60px; vertical-align: left;"></a> </li>
                      <li style="padding-bottom: 6px;"><strong>2024.09.20:</strong> ‚ú®‚ú® <a href="https://brain.ieee.org/2024-ieee-brain-discovery-neurotechnology-workshop/">Travel Award</a>, 2024 IEEE Brain Discovery & Neurotechnology Workshop, &nbsp<a href="https://brain.ieee.org/"><img src="logo/IEEEBrain.png" alt="IEEEBrain Logo" style="width:60px; vertical-align: left;"></a> </li>
                      <li style="padding-bottom: 6px;"><strong>2024.07.29:</strong> üî•üî• <a href="https://www.asilomarssc.org/">P3T: A Transformer Model for Enhancing Character Recognition Rates in P300 Speller Systems</a>, is accpeted by 58th Annual IEEE Asilomar Conference on Signals, Systems, and Computers (ACSSC 2024), &nbsp<a href="https://signalprocessingsociety.org/blog/acssc-2024-2024-asilomar-conference-signals-systems-and-computers"><img src="logo/IEEESignalProcessing.png" alt="IEEESignalProcessing Logo" style="width:55px; vertical-align: middle;"></a>  </li>
                      <li style="padding-bottom: 6px;"><strong>2024.05.10:</strong> ‚ú®‚ú® <a href="https://www.linkedin.com/feed/update/urn:li:activity:7202322991030894592/">Best TA Award</a>, Rutgers University ECE department 2023 Fall, &nbsp<a href="https://www.ece.rutgers.edu/"><img src="logo/Rutgers-ECE.png" alt="IEEEBrain Logo" style="width:100px; vertical-align: middle;"></li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>
           

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Research Background</h2>
                    <p>
                      In Fall 2024, I worked as a Research Intern at Emotiv, focusing on Foundation Models and Generative AI for Brain-Computer Interface (BCI) applications. At Rutgers in 2024, I designed a P300 Speller BCI incorporating Generative AI. In 2023, I developed an LLM-based BCI mind-controlled speller system aimed at assisting individuals with disabilities in communication. In 2022, I created a channel selection method to enhance the speed and efficiency of BCIs in real-world applications. In 2020, I proposed a geometric approach to optimize the k-means algorithm, addressing issues related to local minima. Before joining Rutgers University in 2019, I conducted biostatistics research at Harvard Medical School, focusing on pancreatic cancer diagnosis. This project utilized Gene Set Enrichment Analysis (GSEA) to identify significant biological differences using protein data, including subsets of around 1300 proteins and small gene panels with as few as 5-10 genes.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>

                <!-- Publication Entry with Image -->
                <tr class="publication-entry">
                  <td>
                    <img src='images/ISBI2025.png' alt="ISBI 2025" />
                  </td>
                  <td class="publication-text">
                    <a href="https://biomedicalimaging.org/2025/">
                      <span class="papertitle">TopoEEG: a TimeSformer-Based Topographic Image Representation Method for Single-Trial Early Detection of P300</span>
                    </a>
                    <br>
                    <strong>Jiazhen Hong</strong>,
                    <a href="https://eceweb1.rutgers.edu/~laleh/#/people/PI">Laleh Najafizadeh</a>,
                    <br>
                    <em>ISBI</em>, 2025 IEEE International Symposium on Biomedical Imaging
                    <br>
                    <a href="https://biomedicalimaging.org/2025/">Link</a>
                    <p> We introduce TopoEEG, an innovative image-based framework that generates sequences of topographic maps from EEG data, preserving both temporal and spatial information for decoding neural dynamics. These topographic maps are processed using TimeSformer, a state-of-the-art video classification model with joint and divided space-time attention mechanisms.  </p>
                  </td>
                </tr>

                <!-- Publication Entry with Image -->
                <tr class="publication-entry">
                  <td>
                    <img src='images/ChatBCI.png' alt="Journal 2024" />
                  </td>
                  <td class="publication-text">
                    <a href="https://www.asilomarsscconf.org/">
                      <span class="papertitle">ChatBCI: A P300 Speller BCI Leveraging Large Language Models for Improved Sentence Composition in Realistic Scenarios</span>
                    </a>
                    <br>
                    <strong>Jiazhen Hong</strong>,
                    <a href="https://weinanwang-ru.github.io/">Weinan Wang</a>,
                    <a href="https://eceweb1.rutgers.edu/~laleh/#/people/PI">Laleh Najafizadeh</a>,
                    <br>
                    <em>IEEE Brain</em>, 2024 IEEE Brain Discovery and Neurotechnology Workshop. 
                    <br>
                    <a href="https://arxiv.org/abs/2411.15395">arXiv</a>
                    <p> We present ChatBCI, an innovative P300 speller BCI that leverages the zero-shot learning capability of large language models (LLMs) to improve the speed of sentence writing for the user. The system retrieves word suggestions to either complete partially spelled words or predict the next word in a sentence, improving efficiency when in sentence composition. </p>
                  </td>
                </tr>


                <!-- Publication Entry with Image -->
                <tr class="publication-entry">
                  <td>
                    <img src='images/P3T.png' alt="Asilomar 2024" />
                  </td>
                  <td class="publication-text">
                    <a href="https://www.asilomarsscconf.org/">
                      <span class="papertitle">P3T: A Transformer Model for Enhancing Character Recognition Rates in P300 Speller Systems</span>
                    </a>
                    <br>
                    <strong>Jiazhen Hong</strong>,
                    <a href="https://eceweb1.rutgers.edu/~laleh/#/people/PI">Laleh Najafizadeh</a>,
                    <br>
                    <em>Asilomar (ACSSC)</em>, 2024 Asilomar Conference on Signals, Systems, and Computers
                    <br>
                    <a href="data/poster/Asilomar2024">Poster</a>
                    <p>We introduce P300-Transformer (P3T), a new single-trial P300 detec- tor transfer model, designed to optimize the information transfer rate (ITR) in P300-BCI speller systems, while maintaining a high character recognition rate.</p>
                  </td>
                </tr>


                <!-- Publication Entry with Video -->
                <tr class="publication-entry">
                  <td>
                    <video id="ffkm-video" width="100%" muted loop controls>
                      <source src="images/ffkm.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </td>
                  <td class="publication-text">
                    <a href="https://arxiv.org/abs/2201.04822">
                      <span class="papertitle">A Geometric Approach to <i>k</i>-means</span>
                    </a>
                    <br>
                    <strong>Jiazhen Hong</strong>, Wei Qian,
                    <a href="https://pages.cs.wisc.edu/%7Eyudongchen/">Yudong Chen</a>,
                    <a href="https://www.ece.rutgers.edu/yuqian-zhang">Yuqian Zhang</a>,
                    <br>
                    <em>arXiv</em>, 2022
                    <br>
                    <a href="https://arxiv.org/abs/2201.04822">arXiv</a>
                    <p>We propose a flexible framework for <i>k</i>-means problem by harnessing the geometric structure of local solutions. It provides a theoretical foundation for future work to design detection routines for varying cluster distributions.</p>
                  </td>
                </tr>

                                
                <!-- Publication Entry with Image -->
                <tr class="publication-entry">
                  <td>
                    <img src='images/embc2022-a.jpg' alt="EMBC 2022" />
                  </td>
                  <td class="publication-text">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9871446">
                      <span class="papertitle">A deep learning framework based on dynamic channel selection for early classification of left and right hand motor imagery tasks</span>
                    </a>
                    <br>
                    <strong>Jiazhen Hong</strong>,
                    <a href="https://scholar.google.com/citations?hl=en&user=ATrih2UAAAAJ&view_op=list_works&sortby=pubdate">Foroogh Shamsi</a>,
                    <a href="https://eceweb1.rutgers.edu/~laleh/#/people/PI">Laleh Najafizadeh</a>,
                    <br>
                    <em>EMBC</em>, 2022
                    <br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9871446">IEEE</a> /
                    <a href="data/poster/EMBC2022-poster.pdf">Rutgers Research Day</a> /
                    <a href="data/poster/EMBC2022-BHI.pdf">Rutgers Brain Health Institute Symposium</a>
                    <p>We introduce a deep learning framework that utilizes dynamic channel selection for early classification of left versus right hand motor imagery (MI) tasks. This approach reduces data dimensionality, thereby accelerating future related brain-computer interface (BCI) technologies.</p>
                  </td>
                </tr>
            


                <!-- <script>
                  const video = document.getElementById('ffkm-video');

                  video.addEventListener('click', function() {
                    if (video.paused) {
                      video.play();
                    } else {
                      video.pause();
                    }
                  });
                </script> -->
              </tbody>
            </table>

            <!-- Add Publications Section Here -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>üìÑ Publications</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <div class="publication-section">
              <h3>Accepted</h3>
              <ul>
                <li>J. Hong and L. Najafizadeh, ‚ÄúTopoEEG: a TimeSformer-Based Topographic Image Representation Method for Early Single-Trial Detection of P300,‚Äù 22nd IEEE International Symposium on Biomedical Imaging (ISBI 2025).</li>
                <li>J. Hong, W. Wang and L. Najafizadeh, ‚ÄúChatBCI: A Fast P300 Speller Brain-Computer Interface Incorporating Generative AI-Based Word Prediction</a>, 2024 IEEE Brain Discovery and Neurotechnology Workshop. (Spotlight) ‚Äì Machine Learning and Computer Paradigms for Brain Discovery Posters. </li>
                <li>J. Hong, L. Najafizadeh, ‚ÄúP3T: A Transformer Model for Enhancing Character Recognition Rates in P300 Speller Systems,‚Äù 58th Annual Asilomar Conference on Signals, Systems, and Computers.</li>
                <li>J. Hong, F. Shamsi, and L. Najafizadeh, ‚ÄúA Deep Learning Framework Based on Dynamic Channel Selection for Early Classification of Left and Right Hand Motor Imagery Tasks,‚Äù Proc. of 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC‚Äô22), Glasgow, Scotland, July 2022, pp. 3550-3553.</li>
              </ul>
              <h3>Under Review</h3>
              <ul>
                <li>J. Hong, W. Qian, Y. Chen, and Y. Zhang, ‚ÄúA geometric approach to k-means,‚Äù Under Review.</li>
                <li>J. Hong, W. Wang, and L. Najafizadeh, ‚ÄúChatBCI: A P300 Speller BCI Leveraging Large Language Models for Improved Sentence Composition in Realistic Scenarios,‚Äù Under Review.</li>
                <li>J. Hong, P. Rao, W. Wang, S. Chen and L. Najafizadeh, ‚ÄúChatBCI4ALS: A High-Performance, LLM-Driven Intent-Based BCI Communication System for Individuals with ALS,‚Äù Under Review.</li>
                <li>J. Hong, G. Machellar, and S. Ghane, ‚ÄúEEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling,‚Äù Under Review.</li>
              </ul>
              <h3>In Preparation</h3>
              <ul>
                <li>J. Hong, W. Wang, S. Haghani, and L. Najafizadeh, ‚ÄúSubject-specific Channel Selection Based on Davies-Bouldin Index for EEG Motor Imagery Classification,‚Äù in preparation.</li>
              </ul>
            </div>
          
          <!-- Add News Section Here -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>üßë‚Äçüéì Supervised Students</h2>
                <ul>
                  <li> Pradyumna Rao, Master student in ECE department at Rutgers University (2025) </li>
                  <li> Logan Pasternak, Master student in ECE department at Rutgers University (2025) </li>
                  <li> Joel Paley, Master student in ECE department at Rutgers University (2024) </li>
                  <li> Justin Ding, Master student in ECE department at Rutgers University (2023) </li>
                  <li> William Milne, Master student in ECE department at Rutgers University (2023) </li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>



          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
